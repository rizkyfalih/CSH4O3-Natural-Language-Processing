{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import NLTK terlebih dahulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latihan tokenisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The operation began this morning and all the crews stay in the location'\n",
    "tokens = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'operation', 'began', 'this', 'morning', 'and', 'all', 'the', 'crews', 'stay', 'in', 'the', 'location']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "3\n",
      "operation\n",
      "9\n",
      "began\n",
      "5\n",
      "this\n",
      "4\n",
      "morning\n",
      "7\n",
      "and\n",
      "3\n",
      "all\n",
      "3\n",
      "the\n",
      "3\n",
      "crews\n",
      "5\n",
      "stay\n",
      "4\n",
      "in\n",
      "2\n",
      "the\n",
      "3\n",
      "location\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    print(token)\n",
    "    print(str(len(token)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latihan stemming, import Porter stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "oper\n",
      "began\n",
      "thi\n",
      "morn\n",
      "and\n",
      "all\n",
      "the\n",
      "crew\n",
      "stay\n",
      "in\n",
      "the\n",
      "locat\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "for token in tokens:\n",
    "    stemmed_token = stemmer.stem(token)\n",
    "    print(stemmed_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latihan lemmatization, import WordNet lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "operation\n",
      "began\n",
      "this\n",
      "morning\n",
      "and\n",
      "all\n",
      "the\n",
      "crew\n",
      "stay\n",
      "in\n",
      "the\n",
      "location\n"
     ]
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "for token in tokens:\n",
    "    lemmatized_token = wnl.lemmatize(token)\n",
    "    print(lemmatized_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latihan membangun tabel vocab - frekuensi kemunculan kata, dengan dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_tab = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesilat Indonesia kembali meraih medali emas ke-12, setelah Pipiet Kamelia berhasil menumbangkan pesilat Vietnam Thi Cam Nhi Nguyen di babak final pertandingan cabang olahraga Pencak Silat di ajang Asian Games 2018. Pipiet menang telak 5-0 atas Thi Cam di kelas D putri 60kg-65 kg, yang berlangsung di Padepokan Pencak Silat Taman Mini Indonesia Indah (TMII), Jakarta Timur, Rabu petang. Dengan kemenangan ini, Pipiet berhasil membawa medali emas, sementara Thi Cam harus puas juara kedua dengan medali perak. \n"
     ]
    }
   ],
   "source": [
    "par = 'Pesilat Indonesia kembali meraih medali emas ke-12, setelah Pipiet Kamelia berhasil menumbangkan pesilat Vietnam Thi Cam Nhi Nguyen di babak final pertandingan cabang olahraga Pencak Silat di ajang Asian Games 2018. ' \n",
    "par += 'Pipiet menang telak 5-0 atas Thi Cam di kelas D putri 60kg-65 kg, yang berlangsung di Padepokan Pencak Silat Taman Mini Indonesia Indah (TMII), Jakarta Timur, Rabu petang. '\n",
    "par += 'Dengan kemenangan ini, Pipiet berhasil membawa medali emas, sementara Thi Cam harus puas juara kedua dengan medali perak. '\n",
    "\n",
    "print(par)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pesilat indonesia kembali meraih medali emas ke-12, setelah pipiet kamelia berhasil menumbangkan pesilat vietnam thi cam nhi nguyen di babak final pertandingan cabang olahraga pencak silat di ajang asian games 2018. pipiet menang telak 5-0 atas thi cam di kelas d putri 60kg-65 kg, yang berlangsung di padepokan pencak silat taman mini indonesia indah (tmii), jakarta timur, rabu petang. dengan kemenangan ini, pipiet berhasil membawa medali emas, sementara thi cam harus puas juara kedua dengan medali perak. \n"
     ]
    }
   ],
   "source": [
    "lc_par = par.lower()\n",
    "print(lc_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pesilat', 'indonesia', 'kembali', 'meraih', 'medali', 'emas', 'ke-12', ',', 'setelah', 'pipiet', 'kamelia', 'berhasil', 'menumbangkan', 'pesilat', 'vietnam', 'thi', 'cam', 'nhi', 'nguyen', 'di', 'babak', 'final', 'pertandingan', 'cabang', 'olahraga', 'pencak', 'silat', 'di', 'ajang', 'asian', 'games', '2018.', 'pipiet', 'menang', 'telak', '5-0', 'atas', 'thi', 'cam', 'di', 'kelas', 'd', 'putri', '60kg-65', 'kg', ',', 'yang', 'berlangsung', 'di', 'padepokan', 'pencak', 'silat', 'taman', 'mini', 'indonesia', 'indah', '(', 'tmii', ')', ',', 'jakarta', 'timur', ',', 'rabu', 'petang', '.', 'dengan', 'kemenangan', 'ini', ',', 'pipiet', 'berhasil', 'membawa', 'medali', 'emas', ',', 'sementara', 'thi', 'cam', 'harus', 'puas', 'juara', 'kedua', 'dengan', 'medali', 'perak', '.']\n"
     ]
    }
   ],
   "source": [
    "par_tokens = nltk.word_tokenize(lc_par)\n",
    "print(par_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pesilat': 2, 'indonesia': 2, 'kembali': 1, 'meraih': 1, 'medali': 3, 'emas': 2, 'ke-12': 1, ',': 6, 'setelah': 1, 'pipiet': 3, 'kamelia': 1, 'berhasil': 2, 'menumbangkan': 1, 'vietnam': 1, 'thi': 3, 'cam': 3, 'nhi': 1, 'nguyen': 1, 'di': 4, 'babak': 1, 'final': 1, 'pertandingan': 1, 'cabang': 1, 'olahraga': 1, 'pencak': 2, 'silat': 2, 'ajang': 1, 'asian': 1, 'games': 1, '2018.': 1, 'menang': 1, 'telak': 1, '5-0': 1, 'atas': 1, 'kelas': 1, 'd': 1, 'putri': 1, '60kg-65': 1, 'kg': 1, 'yang': 1, 'berlangsung': 1, 'padepokan': 1, 'taman': 1, 'mini': 1, 'indah': 1, '(': 1, 'tmii': 1, ')': 1, 'jakarta': 1, 'timur': 1, 'rabu': 1, 'petang': 1, '.': 2, 'dengan': 2, 'kemenangan': 1, 'ini': 1, 'membawa': 1, 'sementara': 1, 'harus': 1, 'puas': 1, 'juara': 1, 'kedua': 1, 'perak': 1}\n"
     ]
    }
   ],
   "source": [
    "freq_tab = {}\n",
    "total_count = 0\n",
    "for token in par_tokens:\n",
    "    if token in freq_tab:\n",
    "        freq_tab[token] += 1\n",
    "    else:\n",
    "        freq_tab[token] = 1\n",
    "    total_count += 1\n",
    "        \n",
    "print(freq_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pesilat': 0.022988505747126436, 'indonesia': 0.022988505747126436, 'kembali': 0.011494252873563218, 'meraih': 0.011494252873563218, 'medali': 0.034482758620689655, 'emas': 0.022988505747126436, 'ke-12': 0.011494252873563218, ',': 0.06896551724137931, 'setelah': 0.011494252873563218, 'pipiet': 0.034482758620689655, 'kamelia': 0.011494252873563218, 'berhasil': 0.022988505747126436, 'menumbangkan': 0.011494252873563218, 'vietnam': 0.011494252873563218, 'thi': 0.034482758620689655, 'cam': 0.034482758620689655, 'nhi': 0.011494252873563218, 'nguyen': 0.011494252873563218, 'di': 0.04597701149425287, 'babak': 0.011494252873563218, 'final': 0.011494252873563218, 'pertandingan': 0.011494252873563218, 'cabang': 0.011494252873563218, 'olahraga': 0.011494252873563218, 'pencak': 0.022988505747126436, 'silat': 0.022988505747126436, 'ajang': 0.011494252873563218, 'asian': 0.011494252873563218, 'games': 0.011494252873563218, '2018.': 0.011494252873563218, 'menang': 0.011494252873563218, 'telak': 0.011494252873563218, '5-0': 0.011494252873563218, 'atas': 0.011494252873563218, 'kelas': 0.011494252873563218, 'd': 0.011494252873563218, 'putri': 0.011494252873563218, '60kg-65': 0.011494252873563218, 'kg': 0.011494252873563218, 'yang': 0.011494252873563218, 'berlangsung': 0.011494252873563218, 'padepokan': 0.011494252873563218, 'taman': 0.011494252873563218, 'mini': 0.011494252873563218, 'indah': 0.011494252873563218, '(': 0.011494252873563218, 'tmii': 0.011494252873563218, ')': 0.011494252873563218, 'jakarta': 0.011494252873563218, 'timur': 0.011494252873563218, 'rabu': 0.011494252873563218, 'petang': 0.011494252873563218, '.': 0.022988505747126436, 'dengan': 0.022988505747126436, 'kemenangan': 0.011494252873563218, 'ini': 0.011494252873563218, 'membawa': 0.011494252873563218, 'sementara': 0.011494252873563218, 'harus': 0.011494252873563218, 'puas': 0.011494252873563218, 'juara': 0.011494252873563218, 'kedua': 0.011494252873563218, 'perak': 0.011494252873563218}\n"
     ]
    }
   ],
   "source": [
    "prob_tab = {}\n",
    "for token in freq_tab:\n",
    "    prob_tab[token] = freq_tab[token]/total_count\n",
    "    \n",
    "print(prob_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pesilat\n",
      "indonesia\n",
      "meraih\n",
      "emas\n",
      "1.3964100845175457e-07\n"
     ]
    }
   ],
   "source": [
    "test_sentence = 'Pesilat Indonesia meraih emas'\n",
    "lc_test_sentence = test_sentence.lower()\n",
    "test_tokens = nltk.word_tokenize(lc_test_sentence)\n",
    "total_prob = 1.0\n",
    "for test_token in test_tokens:\n",
    "    total_prob = total_prob * prob_tab[test_token]\n",
    "    print(test_token)\n",
    "    \n",
    "print(total_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
